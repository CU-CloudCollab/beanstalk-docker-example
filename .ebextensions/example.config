option_settings:
  aws:autoscaling:asg:
    # How many EC2 intances do we want running out application?
    MinSize: 1
    MaxSize: 1
  aws:autoscaling:launchconfiguration:
    # What instance size should be used.
    InstanceType: t2.nano
    # This should be replaced by the security group created by the EFS CloudFormation template.
    SecurityGroups: sg-e57b6f9e # REPLACE
  aws:ec2:vpc:
    # This should be replaced by your Cornell VPC id.
    VPCId: vpc-71070114 # REPLACE
    # For example purposes, deploy both the EC2 instances and the ELB in your private subnets.
    Subnets: "subnet-7704a001,subnet-dd8519f6" # REPLACE
    ELBSubnets: "subnet-7704a001,subnet-dd8519f6" # REPLACE
    # This tells EB to create the ELB with only a private address.
    ELBScheme: internal
    # Don't associate a public addresses with EC2 insances launched
    AssociatePublicIpAddress: false
  aws:elasticbeanstalk:application:environment:
    # These values get set in the EC2 shell environment at launch
    key1: example-value1
    # This should be replaced by the EFS created by the EFS CloudFormation template.
    TARGET_EFS_ID: fs-4a1adc03 # REPLACE
  aws:elasticbeanstalk:environment:
    # LoadBalanced the application so we can play with multiple instances later.
    EnvironmentType: LoadBalanced
packages:
  yum:
    # We need nfs-utils in order to mount EFS targets.
    nfs-utils: []
    # Nice to have nano on instances if you are not a VIM user.
    nano: []
files:
  # This file is a stand-in for real content stored on the EFS. It would
  # normally be created and maintained entirely separately from the EB enviroment.
  "/tmp/index.html":
    mode: "000755"
    owner: root
    group: root
    content: |
      <html><body>
      <h1>EFS-Based File</h1>
      <p>This is just a sample file for demonstration purposes.
      In this scenario, there would be another mechanism for creating and
      updating files on the persistent EFS.<p>
      </body></html>
  # This script mounts the EFS files system on an EC2 instance. It is invoked
  # in the "commands" section below.
  "/tmp/mount-efs.sh":
    mode: "000755"
    owner: root
    root: root
    content: |
      #!/bin/bash

      # EFS endpoints are created one per availbility zone (i.e. subnet in our case)
      EC2_AVAIL_ZONE=`curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone`

      # A hack to compute the AWS region, since it is not available directly
      # via instance metadata.
      EC2_REGION="`echo \"$EC2_AVAIL_ZONE\" | sed -e 's:\([0-9][0-9]*\)[a-z]*\$:\\1:'`"

      # Construct the EFS endpoint string
      ENDPOINT=$EC2_AVAIL_ZONE.$TARGET_EFS_ID.efs.$EC2_REGION.amazonaws.com:/

      # Mount the endpoint
      mount -t nfs4 -o nfsvers=4.1 $ENDPOINT /mnt/efs

      # Docker needs to be restarted to become aware of the new file system.
      service docker restart
commands:
  # Create a directory to which the EFS will be mouned,
  # only if it does not already exist.
  010-make-mount-point:
    command: "mkdir /mnt/efs"
    test: "[ ! -d /mnt/efs ]"
  # Execute the script to mount the EFS, if it isn't already mounted (i.e.,
  # listed in /proc/mounts).
  020-mount-efs:
    command: "/tmp/mount-efs.sh"
    test: "! grep -qs '/mnt/efs ' /proc/mounts"
  # Copy our example content to EFS sto ensure something is there (only if
  # nothing is there yet.)
  030-populate-efs:
    command: "cp -p /tmp/index.html /mnt/efs"
    test: "[ ! -f /mnt/efs/index.html ]"

